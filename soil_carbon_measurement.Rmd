---
title: "Measuring Soil Organic Carbon"
author: "Jacob Spertus"
date: "`r Sys.Date()`"
output: html_document
header-includes:
  -\usepackage{amsmath}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```


```{r, message = FALSE}
library(tidyverse)
source("functions.R")
set.seed(100)
```

# Introduction 

Scientists interested in soil organic carbon (SOC) sequestration, need to be able to estimate the average concentration of SOC in a bounded plot. Average concentration expressed in percent SOC is interesting in its own right, and is also a key quantity in estimating the total amount of SOC in a plot, typically expressed in tons of SOC per hectare (Mg ha$^{-1}$). To estimate the average \% SOC, random samples are taken from a plot, possibly mixed together (composited), and then measured. The gold standard measurement method is dry combustion in an elemental analyzer (DC-EA). While precise compared to other measurement methods, DC-EA is still prone to error. In this notebook, we formalize measurement error in SOC assays, investigate some of its properties, and derive a way to estimate measurement error variance using replicated assays. 

# Multiplicative Measurement Error Model

We need a model for measurement error. Suppose a sample is selected at random from a plot and has true (fixed, unknown) SOC concentration $s$. An assay estimates $s$ with some error. Call $S_i$ a single measurement of $s$, and suppose we have $r$ replicates $\{S_1,...,S_r\}$. Let $\delta_i$ be a random variable, the measurement error, that perturbs $s$. An additive measurement error model is typical and assumes $S_i = s + \delta_i$. Additive measurement error does not really make sense for a \%SOC assay because \%SOC is bounded between 0\% and 100\% (negative \%SOC is impossible) and because the physics of measurement point to multiplicative measurement error. Specifically, in DC-EA a common source of error is poor weighing of the tiny aliquots to be combusted. Since the mass of the aliquot is in the denominator when converting from mass CO$_2$ released to \%SOC, the effect of these errors is likely multiplicative. Soil scientists generally expect errors in measurement to be larger when the $s$ is larger. 

The multiplicative measurement error model asserts that $S_i = s \delta_i$. In order for $S_i$ to provide an unbiased estimate of $s$, we need to assume $\mathbb{E}(\delta_i) = 1$. In some $s$ itself is random (i.e. when we consider it a random sample from a plot), in this case we also need $s$ and $\delta_i$ to be independent. We also assume that $\delta_i$ has variance $\sigma_\delta^2$, which does not depend on $s$. The variance of $S_i$ is $\mathbb{V}(S_i) = s^2 \sigma_\delta^2$. Thus while the variance of the perturbations $\delta_i$ is constant, the variance of the measurements themselves depends on $s$. 


# Estimating $s$ and $\sigma_\delta^2$ 

The sample mean of replicates is
$$\bar{S} \equiv \frac{1}{r} \sum_{i=1}^r S_i$$
and yields an unbiased estimate of $s$ in the sense that $\mathbb{E}(\bar{S}) = s$. Furthermore, the variance of $\bar{S}$ is 
$$\mathbb{V}(\bar{S}) = \frac{\mathbb{V}(S_i)}{r} = \frac{s^2 \sigma_\delta^2}{r}$$
In typical fashion, the variance in estimating $s$ can be reduced either by employing a more precise measurement (lower $\sigma_\delta^2$) or by running more replicates (higher $r$). An unbiased estimator of $\mathbb{V}(S_i)$ is the sample variance over replicates:
$$\widehat{\mathbb{V}}(S_i) = \frac{1}{r-1} \sum_{i=1}^r (S_i - \bar{S})^2$$
Note that we can write $\sigma_\delta^2 = \mathbb{V}(S_i) / s^2$. $\bar{S}^2$ is not an unbiased estimator of $s^2$, but note we can use the computational form of the variance of $\bar{S}$ to write $s^2 = \mathbb{E}(\bar{S}^2) - \mathbb{V}(\bar{S})$. Thus an unbiased estimator of $s^2$ is:
$$\widehat{s^2} = \bar{S}^2 - \widehat{\mathbb{V}}(S_i) / r$$
Putting together the pieces, we can estimate $\sigma_\delta^2$ by:
$$\hat{\sigma}_\delta^2 = \frac{\widehat{\mathbb{V}}(S_i)}{\widehat{s^2}}.$$

Note that the square root of this quantity estimates the standard deviation of measurement error, and this is very similar to the "percent difference" between two assays defined as:

$$\mbox{PD}(S_i, S_j) = \frac{|S_i - S_j|}{\frac{1}{2}(S_i + S_j)}$$

To see the similarity with $\hat{\sigma}_\delta$, note that the numerator estimates the spread in the assays and the denominator estimates the true value $s$. The percent difference is sometimes employed by labs to check the measurement error of their assays. 


# Sequential Measurement and Truncated Error

The percent difference may be employed in a sequential manner to gather assays until they are deemed precise enough. Specifically, an investigator might take measurements of samples sequentially until two samples are within say 10\% of each other, as measured by percent difference. This process can introduce bias into measurement unless we are willing to make further assumptions. Specifically, sequentially running assays in this way will lead to unbiased measurement _if_ the measurement error distribution is symmetric. Otherwise, there could be bias. We now demonstrate measurement error through simulation. 


We first define the function `add_symmetric_measurement_error()` which simulates measurement errors from a specific distribution (a shifted and scaled beta distribution).

```{r}
add_symmetric_measurement_error <- function(true_sample, error_bounds, error_sd, replicates = 1){
  #corrupts samples with independent, symmetric, beta distributed measurement error 
  #inputs:
  #true_sample: a length 1 vector of samples
  #error_bounds: a length-2 vector specifying the lower and upper bounds of the error, the mean of these (halfway between the left and right bound) is the expected value of the measurement error
  #replicates: the number of times to measure each sample (duplicate, triplicate, etc)
  #output: 
  #the measured samples a vector of length replicates
  if(error_sd^2 > (1/4)*(error_bounds[2] - error_bounds[1])^2){
    stop("error variance is too big given the error bounds!")
  }
  alpha <- (error_bounds[1] - error_bounds[2])^2 / (8 * error_sd^2) - 1/2
  delta_star <- rbeta(length(true_sample)*replicates, shape1 = alpha, shape2 = alpha)
  delta <- (delta_star - 1/2) * abs(error_bounds[1] - error_bounds[2]) + mean(error_bounds)
  samples_frame <- expand.grid("sample" = rep(1:length(true_sample)), "measurement_replicate" = rep(1:replicates))
  
  measured_samples <- rep(true_sample, replicates) * delta
  measured_samples
}
```


This is what the distribution looks like for a bound of [.5,1.5] and $\sigma_\delta = .1$

```{r}
hist(add_symmetric_measurement_error(true_sample = 1, error_bounds = c(.5,1.5), error_sd = 0.1, replicates = 5000), breaks = 30, main = "Symmetric measurement error", xlab = "Error")
```

Now we demonstrate that the measurements are unbiased under symmetric, mean 1 measurement error, even when assays are selected using a sequential rule.

```{r}
#a grid of true concentrations from .1 to 5 percent SOC
samples <- seq(.1, 20, length.out = 50)

#simulate a bunch of measurements
measured_samples <- sapply(samples, add_symmetric_measurement_error, error_bounds = c(.5,1.5), error_sd = .1, replicates = 500)

#measurement is unbiased for any s if we don't do any thresholding
plot(x = samples, y = colMeans(measured_samples), pch = 20, cex = 1.5, xlab = "True value of s", ylab = "Expected Value of Measurements")
abline(0,1)

#sequential thresholding function
get_sequential_duplicates <- function(measured_samples, threshold = .1){
  sequential_differences <- apply(measured_samples, 2, diff)
  sequential_averages <- apply(measured_samples, 2, zoo::rollmean, k = 2)
  sequential_pct_differences <- abs(sequential_differences) / sequential_averages
  sequential_duplicates <- apply(sequential_pct_differences, 2, function(x){min(which(x < threshold))})
  duplicate_estimate <- sequential_averages[cbind(sequential_duplicates,1:ncol(sequential_averages))]
  duplicate_estimate
}

#simulate the measurement process a bunch of times
run_simulation <- function(true_samples, error_bounds, error_sd, threshold){
  measured_samples <- sapply(true_samples, add_symmetric_measurement_error, error_bounds = error_bounds, error_sd = error_sd, replicates = 50)
  get_sequential_duplicates(measured_samples, threshold = threshold)
}


#now run simulations
simulation_results <- replicate(n = 200, run_simulation(true_samples = samples, error_bounds = c(.5,1.5), error_sd = .15, threshold = .1))
#there is still no bias
plot(y = rowMeans(simulation_results), x = samples, pch = 20, cex = 1.5, xlab = "True value of s", ylab = "Expected value of sequentially thresholded duplicates")
abline(0,1)
```

On the other hand, if the distribution is not symmetric, we may see bias. The function `add_skewed_measurement_error()` adds measurement errors that are skewed so that the mode falls on one side of 1.  

```{r}
add_skewed_measurement_error <- function(true_sample, alpha = 20, beta = 5, replicates = 1){
  #corrupts samples with independent, symmetric, beta distributed measurement error 
  #inputs:
  #alpha: the parameter alpha in the beta distribution
  #beta: the parameter beta in the beta distribution
  #true_sample: a length 1 vector of samples
  #replicates: the number of times to measure each sample (duplicate, triplicate, etc)
  #output: 
  #the measured samples a vector of length replicates

  delta_star <- rbeta(length(true_sample)*replicates, shape1 = alpha, shape2 = beta)
  delta <- (delta_star - alpha/(alpha+beta)) + 1
  samples_frame <- expand.grid("sample" = rep(1:length(true_sample)), "measurement_replicate" = rep(1:replicates))
  
  measured_samples <- rep(true_sample, replicates) * delta
  measured_samples
}
```


These measurement errors can be quite skewed but still have mean 1:

```{r}
skewed_errors <- add_skewed_measurement_error(true_sample = 1, alpha = 10, beta = 1, replicates = 5000)
hist(skewed_errors, breaks = 30, main = "Skewed Measurement Error", xlab = "Error")
mean(skewed_errors)
```

Now we examine the properties of skewed measurement errors:

```{r}
#simulate a bunch of measurements
measured_samples <- sapply(samples, add_skewed_measurement_error, alpha = 10, beta = 1, replicates = 500)

#measurement is still unbiased for any s if we don't do any thresholding
plot(x = samples, y = colMeans(measured_samples), pch = 20, cex = 1.5, xlab = "True value of s", ylab = "Expected Value of Measurements")
abline(0,1)

#simulate the measurement process a bunch of times
run_simulation_skewed <- function(true_samples, alpha, beta, threshold){
  measured_samples <- sapply(true_samples, add_skewed_measurement_error, alpha = alpha, beta = beta, replicates = 50)
  get_sequential_duplicates(measured_samples, threshold = threshold)
}


#now run simulations
simulation_results_skewed <- replicate(n = 200, run_simulation_skewed(true_samples = samples, alpha = 10, beta = 1, threshold = .1))
#there is some bias (esp in higher s samples) if the measurement error distribution is skewed
plot(y = rowMeans(simulation_results_skewed), x = samples, pch = 20, cex = 1.5, xlab = "True value of s", ylab = "Expected value of sequentially thresholded duplicates", main = "Skewed Measurement Error")
abline(0,1)
```




# Effect of imprecise weighing on SOC measurements

Most elemental analyzers specify that aliquots to be assayed should be weighed out to 6 decimal places, that is .000001 grams or .001 milligrams. During combustion, the mass of CO2 released is measured to some precision by the elemental analyzer. The amount of carbon on a gram per gram basis, is then determined by dividing this amount by the exact mass of the soil. The carbon concentration can then be converted into percent, gram per kilogram, etc. 

The measurement error is thus a function of the machine's precision in measuring CO2 released, and the precision of the balance used to weigh the aliquot. If a 5 decimal point balance is used instead of a 6 decimal point balance, then the measurement error of the weighing is increased by a factor of 10. Does this have an appreciable effect on the overall precision of the analysis?

Let $M_i$ be the measured mass in the $i$th run of a sample and $C_i$ be the mass of carbon released during combustion, both in milligrams. The measured concentration of carbon is $S_i = C_i / M_i$. We assume that measurements are unbiased (which can be assured through callibration on standards) such that $\mathbb{E}[S_i] = \mu_S$, where $\mu_S$ is the true concentration in the sample. The variance of $S_i$ is

$$\mathbb{V}[S_i] = \mathbb{V}[C_i / M_i] = \mathbb{V}\bigg [C_i \frac{1}{M_i} \bigg ] = \mathbb{V}[C_i] \mathbb{E}[M_i^{-1}]^2 + \mathbb{V}[M_i^{-1}] \mathbb{E}[C_i]^2 + \mathbb{V}[C_i]\mathbb{V}[M_i^{-1}].$$
$M_i$ is bounded away from 0 so this should be well-defined, but is still difficult to analyze without further assumptions. On the other hand, it is straightforward to simulate the distribution of $S_i$ assuming distributions for $C_i$ and $M_i$. 

#### Normal error

For example, suppose $C_i \sim \mathcal{N}(\mu_C, \sigma_C^2)$ and $M_i \sim \mathcal{N}(\mu_M, \sigma_M)^2$, independently, with $\mu_C$ the true mass of carbon and $\mu_M$ the true mass of the aliquot so $\mu_S = \mu_C / \mu_M$. [Diaz-Frances and Rubio, 2012](https://link.springer.com/article/10.1007/s00362-012-0429-2) derive a normal approximation to the distribution of $S_i = C_i / M_i$, with approximate variance:
$$\sigma_S^2 = \mu_S^2 \bigg( \frac{\sigma_C^2}{\mu_C^2} + \frac{\sigma_M^2}{\mu_M^2} \bigg)$$

The effect of imprecision in weighing is to increase $\sigma_M$, and the effect on $\sigma_S^2$ in turn depends on how much sample is weighed ($\mu_M^2$). Ultimately, if the machine measurement is highly imprecise then the first term inside the parentheses $\sigma_C^2 / \mu_C^2$ will dominate. Here is a function to simulate from the distribution of $S_i$:

```{r}
#inputs: 
  #n: the number of samples to draw of S_i
  #mu_M: the average weighed mass of the aliquot (true mass, assuming unbiased weighing)
  #var_M: the imprecision of the balance used. 
  #mu_C: the average carbon mass measured by the machine (true mass, assuming unbiased measurement)
  #var_C: the error variance of the machine
run_sim <- function(n, mu_M, var_M, mu_C, var_C){
  C <- rnorm(n, mean = mu_C, sd = sqrt(var_C))
  M <- rnorm(n, mean = mu_M, sd = sqrt(var_M))
  S <- C/M
  S
}

#an example where carbon concentration is 1% (.01 gram/gram), with measurement error .1% (absolute on the concentration scale). mu_M = 10 milligrams are weighed at a resolution of .00001 (5 decimal places) or .000001 (6 decimal places) grams. The total mass of carbon released is thus mu_C = .0001 grams = .1 milligrams.  
#sigma_M = .000005 puts 95% of the mass measurements within .00001 grams of the true mass.
#For sigma_C, most measurements need to be within .000098 and .00012 in order for concenrations to be within 2 * .1% of the true concentration of .0001. Thus sigma_C = .00001.
sims_5_places <- run_sim(n = 1e6, mu_M = .01, var_M = .000005^2, mu_C = .0001, var_C = .00001^2)
sims_6_places <- run_sim(n = 1e6, mu_M = .01, var_M = .0000005^2, mu_C = .0001, var_C = .00001^2)
#resulting overall measurement error (in sd)
sd(sims_5_places)
sd(sims_6_places)
#ratio of errors. How much is the error inflated by less precision in weighing?
sd(sims_5_places) / sd(sims_6_places) 
```

The simulated measurement error is about .001 grams, so 95% of measurements are in about 0.002 gram/gram or .2 percent of the true concentration. This aligns with the standard deviation of .1 percent for SoliTOC given by Elementar. 0.001 grams is essentially just the error of the machine, so in this case the effect of more imprecise weighing is completely negligible. This also tracks with the analytical approximation:

$$0.01^2 \bigg( \frac{0.00001^2}{0.0001^2} + \frac{0.00005^2}{.01^2} \bigg) \bigg / 0.01^2 \bigg( \frac{0.00001^2}{0.0001^2} + \frac{0.000005^2}{.01^2} \bigg)$$
```{r}
(.00001^2 / .0001^2 + .00005^2/.01^2) / (.00001^2 / .0001^2 + 0.000005^2/.01^2)
```

If the error of measurement with the instrument is always .1% (as indicated by Elementar) then $\sigma_C / \mu_S = .001$ (here the true concentration is 1%, so $\sigma_C = .001 * .01 = .00001$. If it is 2% so $\mu_S = .02$, $\sigma_C = .00002$ and so on). The contribution from instrumental error is always pegged to the true concentration, which isn't effected by the amount of sample weighed out. But this quantity, $\mu_M$, does effect the contribution from weighing error, so at very small aliquot masses the weighing error can dominate the overall measurement error $\sigma_S$. The simulations above seem to indicate that this doesn't happen down to 10mg and 1% concentration, which in practice is likely a worst case scenario for weighing. 


